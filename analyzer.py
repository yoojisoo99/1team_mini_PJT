"""
íˆ¬ì ì„±í–¥ ë¶„ì„ & ì¢…ëª© ì¶”ì²œ ì—”ì§„
================================
í•œì–‘ì¦ê¶Œ íˆ¬ìì„±í–¥ì§„ë‹¨ ê¸°ì¤€ 5ë‹¨ê³„ ë¶„ë¥˜:
  ì•ˆì •í˜• â†’ ì•ˆì •ì¶”êµ¬í˜• â†’ ìœ„í—˜ì¤‘ë¦½í˜• â†’ ì ê·¹íˆ¬ìí˜• â†’ ê³µê²©íˆ¬ìí˜•

ì„¤ë¬¸ 11ë¬¸í•­ì— ëŒ€í•œ ì ìˆ˜ë¥¼ í•©ì‚°í•˜ì—¬ íˆ¬ì ì„±í–¥ì„ ë¶„ë¥˜í•˜ê³ ,
ì„±í–¥ì— ë§ëŠ” ì¢…ëª© ì¶”ì²œ ìŠ¤ì½”ì–´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

# ============================================================
# 1. íˆ¬ì ì„±í–¥ ì„¤ë¬¸ ì •ì˜ (í•œì–‘ì¦ê¶Œ ê¸°ì¤€ 11ë¬¸í•­)
# ============================================================
SURVEY_QUESTIONS = [
    {
        'id': 'q1',
        'question': 'ê³ ê°ë‹˜ì˜ ì—°ë ¹ëŒ€ëŠ” ì–´ë–»ê²Œ ë˜ì‹­ë‹ˆê¹Œ?',
        'options': [
            ('ë§Œ 19ì„¸ ì´í•˜', 1),
            ('ë§Œ 20ì„¸~30ì„¸', 5),
            ('ë§Œ 31ì„¸~54ì„¸', 4),
            ('ë§Œ 55ì„¸~64ì„¸', 3),
            ('ë§Œ 65ì„¸ ì´ìƒ', 1),
        ],
    },
    {
        'id': 'q2',
        'question': 'íˆ¬ìí•˜ì‹¤ ìê¸ˆì˜ íˆ¬ìê°€ëŠ¥ ê¸°ê°„ì€ ì–´ëŠ ì •ë„ì…ë‹ˆê¹Œ?',
        'options': [
            ('6ê°œì›” ë¯¸ë§Œ', 1),
            ('6ê°œì›” ì´ìƒ~1ë…„ ë¯¸ë§Œ', 2),
            ('1ë…„ ì´ìƒ~2ë…„ ë¯¸ë§Œ', 3),
            ('2ë…„ ì´ìƒ~3ë…„ ë¯¸ë§Œ', 4),
            ('3ë…„ ì´ìƒ', 5),
        ],
    },
    {
        'id': 'q3',
        'question': 'ë‹¤ìŒ ì¤‘ íˆ¬ìê²½í—˜ê³¼ ê°€ì¥ ê°€ê¹Œìš´ ìƒí’ˆì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?',
        'options': [
            ('ì€í–‰ ì˜ˆ/ì ê¸ˆ, êµ­ì±„, MMF, CMA ë“±', 1),
            ('ê¸ˆìœµì±„, íšŒì‚¬ì±„, ì±„ê¶Œí˜• í€ë“œ ë“±', 2),
            ('í˜¼í•©í˜• í€ë“œ, ì›ê¸ˆ ì¼ë¶€ ë³´ì¥ ELS ë“±', 3),
            ('ì£¼ì‹, ì›ê¸ˆ ë¹„ë³´ì¥ ELS, ì£¼ì‹í˜• í€ë“œ ë“±', 4),
            ('ELW, ì„ ë¬¼ì˜µì…˜, íŒŒìƒìƒí’ˆ í€ë“œ, ì‹ ìš©ê±°ë˜ ë“±', 5),
        ],
    },
    {
        'id': 'q4',
        'question': 'ê¸ˆìœµíˆ¬ììƒí’ˆ íˆ¬ìê²½í—˜ ê¸°ê°„ì€ ì–´ë–»ê²Œ ë˜ì‹­ë‹ˆê¹Œ?',
        'options': [
            ('ì „í˜€ ì—†ìŒ', 1),
            ('1ë…„ ë¯¸ë§Œ', 2),
            ('1ë…„ ì´ìƒ~3ë…„ ë¯¸ë§Œ', 3),
            ('3ë…„ ì´ìƒ~5ë…„ ë¯¸ë§Œ', 4),
            ('5ë…„ ì´ìƒ', 5),
        ],
    },
    {
        'id': 'q5',
        'question': 'ê¸ˆìœµíˆ¬ììƒí’ˆ ì·¨ë“ ë° ëª©ì ì€ ì–´ë–¤ ê²ƒì…ë‹ˆê¹Œ?',
        'options': [
            ('ì±„ë¬´ìƒí™˜', 1),
            ('ìƒí™œë¹„', 2),
            ('ì£¼íƒë§ˆë ¨', 3),
            ('ì—¬ìœ ìê¸ˆ', 4),
            ('ìì‚°ì¦ì‹', 5),
        ],
    },
    {
        'id': 'q6',
        'question': 'ê¸ˆìœµíˆ¬ììƒí’ˆ íˆ¬ìì— ëŒ€í•œ ì§€ì‹ìˆ˜ì¤€ì€ ì–´ëŠ ì •ë„ì…ë‹ˆê¹Œ?',
        'options': [
            ('ê¸ˆìœµìƒí’ˆì— íˆ¬ìí•´ ë³¸ ê²½í—˜ì´ ì—†ìŒ', 1),
            ('ì£¼ì‹, ì±„ê¶Œ, í€ë“œ ë“±ì˜ êµ¬ì¡° ë° ìœ„í—˜ì„ ì¼ì • ë¶€ë¶„ ì´í•´', 3),
            ('ì£¼ì‹, ì±„ê¶Œ, í€ë“œ ë“±ì˜ êµ¬ì¡° ë° ìœ„í—˜ì„ ê¹Šì´ ìˆê²Œ ì´í•´', 4),
            ('íŒŒìƒìƒí’ˆ í¬í•¨ ëŒ€ë¶€ë¶„ì˜ ê¸ˆìœµíˆ¬ììƒí’ˆ ì´í•´', 5),
        ],
    },
    {
        'id': 'q7',
        'question': 'íˆ¬ììˆ˜ìµÂ·íˆ¬ììœ„í—˜ì— ëŒ€í•œ íƒœë„ëŠ” ì–´ë–»ìŠµë‹ˆê¹Œ?',
        'options': [
            ('íˆ¬ììˆ˜ìµì„ ê³ ë ¤í•˜ë‚˜ ì›ê¸ˆë³´ì¡´ ì¶”êµ¬', 1),
            ('ì›ê¸ˆ ë³´ì¡´ì„ ê³ ë ¤í•˜ë‚˜ íˆ¬ììˆ˜ìµ ì¶”êµ¬ ë˜ëŠ” ì†ì‹¤ìœ„í—˜ ê°ìˆ˜', 5),
        ],
    },
    {
        'id': 'q8',
        'question': 'ê³ ê°ë‹˜ì˜ ì´ ìì‚°ì€ ì–´ë–»ìŠµë‹ˆê¹Œ?',
        'options': [
            ('1ì–µ ë¯¸ë§Œ', 1),
            ('1ì–µ ì´ìƒ~2ì–µ ë¯¸ë§Œ', 2),
            ('2ì–µ ì´ìƒ~5ì–µ ë¯¸ë§Œ', 3),
            ('5ì–µ ì´ìƒ~10ì–µ ë¯¸ë§Œ', 4),
            ('10ì–µ ì´ìƒ', 5),
        ],
    },
    {
        'id': 'q9',
        'question': 'í–¥í›„ ìˆ˜ì…ì›ì— ëŒ€í•œ ì˜ˆìƒì€ ì–´ë–»ê²Œ í•˜ê³  ê³„ì‹­ë‹ˆê¹Œ?',
        'options': [
            ('ì¼ì • ìˆ˜ì… + ìœ ì§€ ë˜ëŠ” ì¦ê°€ ì˜ˆìƒ', 5),
            ('ì¼ì • ìˆ˜ì… ìˆìœ¼ë‚˜ ê°ì†Œ/ë¶ˆì•ˆì • ì˜ˆìƒ', 3),
            ('ì¼ì • ìˆ˜ì… ì—†ìœ¼ë©° ì—°ê¸ˆì´ ì£¼ ìˆ˜ì…ì›', 1),
        ],
    },
    {
        'id': 'q10',
        'question': 'ê¸°ëŒ€ì´ìµ ìˆ˜ì¤€ì€ ì–´ë–»ê²Œ ë˜ì‹­ë‹ˆê¹Œ?',
        'options': [
            ('ì›ê¸ˆ ê¸°ì¤€ 10% ë²”ìœ„', 1),
            ('ì›ê¸ˆ ê¸°ì¤€ 20% ë²”ìœ„', 2),
            ('ì›ê¸ˆ ê¸°ì¤€ 50% ë²”ìœ„', 3),
            ('ì›ê¸ˆ ê¸°ì¤€ 70% ë²”ìœ„', 4),
            ('ì›ê¸ˆ ê¸°ì¤€ 100% ë²”ìœ„', 5),
        ],
    },
    {
        'id': 'q11',
        'question': 'ê°ë‚´í•  ìˆ˜ ìˆëŠ” ì†ì‹¤ ìˆ˜ì¤€ì€ ì–´ëŠ ì •ë„ì…ë‹ˆê¹Œ?',
        'options': [
            ('ì›ê¸ˆë³´ì¡´ì¶”êµ¬', 1),
            ('ì›ê¸ˆ ê¸°ì¤€ -10% ë²”ìœ„', 2),
            ('ì›ê¸ˆ ê¸°ì¤€ -20% ë²”ìœ„', 3),
            ('ì›ê¸ˆ ê¸°ì¤€ -50% ë²”ìœ„', 4),
            ('ì›ê¸ˆ ê¸°ì¤€ -70% ë²”ìœ„', 5),
            ('ì „ì•¡ì†ì‹¤ê°ë‚´ê°€ëŠ¥', 6),
        ],
    },
]


# ============================================================
# 2. íˆ¬ì ì„±í–¥ ë¶„ë¥˜
# ============================================================
def classify_investor_type(answers):
    """
    11ë¬¸í•­ ì„¤ë¬¸ ì ìˆ˜ë¥¼ í•©ì‚°í•˜ì—¬ íˆ¬ì ì„±í–¥ì„ 5ë‹¨ê³„ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.

    Args:
        answers: dict - {q1: ì„ íƒ ì¸ë±ìŠ¤(0-based), q2: ..., ...}
    Returns:
        tuple(str, int) - (íˆ¬ìì„±í–¥, ì´ì )
    """
    total_score = 0
    max_possible = 0

    for q in SURVEY_QUESTIONS:
        qid = q['id']
        selected_idx = answers.get(qid, 0)
        # ì„ íƒëœ ì˜µì…˜ì˜ ì ìˆ˜
        if 0 <= selected_idx < len(q['options']):
            total_score += q['options'][selected_idx][1]
        # ìµœëŒ€ ì ìˆ˜
        max_possible += max(score for _, score in q['options'])

    # ì ìˆ˜ ë¹„ìœ¨ë¡œ 5ë‹¨ê³„ ë¶„ë¥˜
    ratio = total_score / max_possible if max_possible > 0 else 0

    if ratio <= 0.25:
        investor_type = 'ì•ˆì •í˜•'
    elif ratio <= 0.40:
        investor_type = 'ì•ˆì •ì¶”êµ¬í˜•'
    elif ratio <= 0.60:
        investor_type = 'ìœ„í—˜ì¤‘ë¦½í˜•'
    elif ratio <= 0.80:
        investor_type = 'ì ê·¹íˆ¬ìí˜•'
    else:
        investor_type = 'ê³µê²©íˆ¬ìí˜•'

    logger.info(f"[ì„±í–¥ ë¶„ë¥˜] ì´ì ={total_score}/{max_possible}, "
                f"ë¹„ìœ¨={ratio:.2%}, ì„±í–¥={investor_type}")
    return investor_type, total_score


# ============================================================
# 3. íˆ¬ì ì„±í–¥ë³„ ì¢…ëª© ìŠ¤ì½”ì–´ë§
# ============================================================

# ì„±í–¥ë³„ ê°€ì¤‘ì¹˜ í”„ë¡œí•„
WEIGHT_PROFILES = {
    'ì•ˆì •í˜•': {
        'ë°°ë‹¹ìˆ˜ìµë¥ ': 0.30,
        'ì‹œê°€ì´ì•¡_ìˆœìœ„': 0.25,     # ëŒ€í˜•ì£¼ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        'ë³€ë™í­_ì—­ìˆœìœ„': 0.25,    # ë³€ë™í­ì´ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        'PBR_ì—­ìˆœìœ„': 0.10,       # ë‚®ì€ PBR (ì €í‰ê°€)
        'ê¸°ê´€_ìˆœë§¤ìˆ˜': 0.10,
    },
    'ì•ˆì •ì¶”êµ¬í˜•': {
        'ë°°ë‹¹ìˆ˜ìµë¥ ': 0.20,
        'ì‹œê°€ì´ì•¡_ìˆœìœ„': 0.20,
        'ê¸°ê´€_ìˆœë§¤ìˆ˜': 0.20,
        'PER_ì ì •': 0.20,         # PERì´ ì ì • ë²”ìœ„
        'ë³€ë™í­_ì—­ìˆœìœ„': 0.20,
    },
    'ìœ„í—˜ì¤‘ë¦½í˜•': {
        'ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜': 0.25,
        'PER_ì ì •': 0.20,
        'ê±°ë˜ëŸ‰_ìˆœìœ„': 0.20,
        'ì‹œê°€ì´ì•¡_ìˆœìœ„': 0.15,
        'ë“±ë½ë¥ _ì ˆëŒ€ê°’': 0.20,
    },
    'ì ê·¹íˆ¬ìí˜•': {
        'ê±°ë˜ëŸ‰_ìˆœìœ„': 0.30,
        'ë“±ë½ë¥ _ì ˆëŒ€ê°’': 0.25,
        'ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜': 0.20,
        'ë³€ë™í­_ìˆœìœ„': 0.15,      # ë³€ë™í­ì´ ë†’ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        'PER_ì ì •': 0.10,
    },
    'ê³µê²©íˆ¬ìí˜•': {
        'ê±°ë˜ëŸ‰_ìˆœìœ„': 0.35,
        'ë“±ë½ë¥ _ì ˆëŒ€ê°’': 0.30,
        'ë³€ë™í­_ìˆœìœ„': 0.20,
        'ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜': 0.15,
    },
}

# ì„±í–¥ë³„ ì„¤ëª…
TYPE_DESCRIPTIONS = {
    'ì•ˆì •í˜•': {
        'emoji': 'ğŸ›¡ï¸',
        'title': 'ì•ˆì •í˜• íˆ¬ìì',
        'desc': 'ì˜ˆê¸ˆ ë˜ëŠ” ì ê¸ˆ ìˆ˜ì¤€ì˜ ìˆ˜ìµë¥ ì„ ê¸°ëŒ€í•˜ë©°, '
                'íˆ¬ìì›ê¸ˆì— ì†ì‹¤ì´ ë°œìƒí•˜ëŠ” ê²ƒì„ ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.',
        'strategy': 'ê³ ë°°ë‹¹ ëŒ€í˜• ìš°ëŸ‰ì£¼, ë‚®ì€ ë³€ë™ì„± ì¢…ëª© ìœ„ì£¼ ì¶”ì²œ',
        'color': '#2E86AB',
    },
    'ì•ˆì •ì¶”êµ¬í˜•': {
        'emoji': 'ğŸ”’',
        'title': 'ì•ˆì •ì¶”êµ¬í˜• íˆ¬ìì',
        'desc': 'íˆ¬ì ì›ê¸ˆì˜ ì†ì‹¤ìœ„í—˜ì€ ìµœì†Œí™”í•˜ê³ , '
                'ì´ìì†Œë“ì´ë‚˜ ë°°ë‹¹ì†Œë“ ìˆ˜ì¤€ì˜ ì•ˆì •ì ì¸ íˆ¬ìë¥¼ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. '
                'ì˜ˆÂ·ì ê¸ˆë³´ë‹¤ ë†’ì€ ìˆ˜ìµì„ ìœ„í•´ ì¼ë¶€ ë³€ë™ì„±ì„ í—ˆìš©í•©ë‹ˆë‹¤.',
        'strategy': 'ë°°ë‹¹+ê°€ì¹˜ì£¼, ê¸°ê´€ ìˆœë§¤ìˆ˜ ì–‘í˜¸ ì¤‘ëŒ€í˜•ì£¼ ì¶”ì²œ',
        'color': '#A23B72',
    },
    'ìœ„í—˜ì¤‘ë¦½í˜•': {
        'emoji': 'âš–ï¸',
        'title': 'ìœ„í—˜ì¤‘ë¦½í˜• íˆ¬ìì',
        'desc': 'íˆ¬ìì—ëŠ” ê·¸ì— ìƒì‘í•˜ëŠ” ìœ„í—˜ì´ ìˆìŒì„ ì¶©ë¶„íˆ ì¸ì‹í•˜ê³  ìˆìœ¼ë©°, '
                'ì˜ˆÂ·ì ê¸ˆë³´ë‹¤ ë†’ì€ ìˆ˜ìµì„ ê¸°ëŒ€í•  ìˆ˜ ìˆë‹¤ë©´ ì¼ì • ìˆ˜ì¤€ì˜ ì†ì‹¤ì„ ê°ìˆ˜í•©ë‹ˆë‹¤.',
        'strategy': 'ì„±ì¥ì£¼, ì ì • PER, ì™¸êµ­ì¸ ë§¤ìˆ˜ ì¢…ëª© ìœ„ì£¼ ì¶”ì²œ',
        'color': '#F18F01',
    },
    'ì ê·¹íˆ¬ìí˜•': {
        'emoji': 'ğŸš€',
        'title': 'ì ê·¹íˆ¬ìí˜• íˆ¬ìì',
        'desc': 'íˆ¬ìì›ê¸ˆì˜ ë³´ì „ë³´ë‹¤ëŠ” ìœ„í—˜ì„ ê°ë‚´í•˜ë”ë¼ë„ '
                'ë†’ì€ ìˆ˜ì¤€ì˜ íˆ¬ììˆ˜ìµ ì‹¤í˜„ì„ ì¶”êµ¬í•©ë‹ˆë‹¤.',
        'strategy': 'ê±°ë˜ëŸ‰ ê¸‰ë“±, ëª¨ë©˜í…€ ì¢…ëª©, ê³ ë³€ë™ì„± ì¶”ì²œ',
        'color': '#C73E1D',
    },
    'ê³µê²©íˆ¬ìí˜•': {
        'emoji': 'ğŸ”¥',
        'title': 'ê³µê²©íˆ¬ìí˜• íˆ¬ìì',
        'desc': 'ì‹œì¥ í‰ê·  ìˆ˜ìµë¥ ì„ í›¨ì”¬ ë„˜ì–´ì„œëŠ” ë†’ì€ ìˆ˜ì¤€ì˜ íˆ¬ììˆ˜ìµì„ ì¶”êµ¬í•˜ë©°, '
                'ìì‚° ê°€ì¹˜ì˜ ë³€ë™ì— ë”°ë¥¸ ì†ì‹¤ ìœ„í—˜ì„ ì ê·¹ ìˆ˜ìš©í•©ë‹ˆë‹¤.',
        'strategy': 'í…Œë§ˆì£¼, ìµœê³  ê±°ë˜ëŸ‰, ê³ ë“±ë½ë¥  ì¢…ëª© ì¶”ì²œ',
        'color': '#D00000',
    },
}


def _normalize_series(s, ascending=True):
    """ì‹œë¦¬ì¦ˆë¥¼ 0~100 ì‚¬ì´ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    s = pd.to_numeric(s, errors='coerce').fillna(0)
    min_v, max_v = s.min(), s.max()
    if max_v == min_v:
        return pd.Series(50, index=s.index)
    normalized = (s - min_v) / (max_v - min_v) * 100
    if not ascending:
        normalized = 100 - normalized
    return normalized


# ============================================================
# [Phase 1] ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° (RSI, MACD, ì´ë™í‰ê· ì„ )
# ============================================================
def calculate_technical_indicators(hist_df):
    """
    ì¢…ëª©ë³„ pykrx OHLCV ë°ì´í„°ì—ì„œ ê¸°ìˆ ì  ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        hist_df: ê³¼ê±° ì‹œì„¸ DataFrame (ì»¬ëŸ¼: ì¢…ëª©ì½”ë“œ, ë‚ ì§œ, ì‹œê°€, ê³ ê°€, ì €ê°€, ì¢…ê°€, ê±°ë˜ëŸ‰)
    Returns:
        DataFrame: ì¢…ëª©ì½”ë“œë³„ ê¸°ìˆ ì  ì§€í‘œ ìš”ì•½
    """
    if hist_df is None or hist_df.empty:
        return pd.DataFrame()

    close_col = 'ì¢…ê°€' if 'ì¢…ê°€' in hist_df.columns else 'Close'
    code_col  = 'ì¢…ëª©ì½”ë“œ' if 'ì¢…ëª©ì½”ë“œ' in hist_df.columns else 'Ticker'

    results = []

    for code, group in hist_df.groupby(code_col):
        group = group.sort_values('ë‚ ì§œ' if 'ë‚ ì§œ' in group.columns else group.index.name)
        closes = group[close_col].astype(float)

        if len(closes) < 2:
            continue

        # â”€â”€ RSI (14ì¼, ë°ì´í„° ë¶€ì¡± ì‹œ ë³´ìœ  ë°ì´í„°ë¡œ ê³„ì‚°) â”€â”€
        delta = closes.diff()
        gain  = delta.clip(lower=0)
        loss  = -delta.clip(upper=0)
        avg_gain = gain.ewm(com=13, adjust=False).mean()
        avg_loss = loss.ewm(com=13, adjust=False).mean()
        rs = avg_gain / avg_loss.replace(0, 1e-9)
        rsi = (100 - 100 / (1 + rs)).iloc[-1]

        # â”€â”€ MACD (12/26/9, ë°ì´í„° ë¶€ì¡± ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ê°„ìœ¼ë¡œ ê³„ì‚°) â”€â”€
        span12 = min(12, len(closes))
        span26 = min(26, len(closes))
        span9  = min(9, len(closes))
        ema12  = closes.ewm(span=span12, adjust=False).mean()
        ema26  = closes.ewm(span=span26, adjust=False).mean()
        macd_line   = ema12 - ema26
        signal_line = macd_line.ewm(span=span9, adjust=False).mean()
        macd_val    = macd_line.iloc[-1]
        macd_signal = signal_line.iloc[-1]
        macd_hist   = macd_val - macd_signal  # ì–‘ìˆ˜: ìƒìŠ¹ ëª¨ë©˜í…€

        # â”€â”€ ì´ë™í‰ê· ì„  (MA5, MA20) â”€â”€
        ma5  = closes.rolling(min(5,  len(closes))).mean().iloc[-1]
        ma20 = closes.rolling(min(20, len(closes))).mean().iloc[-1]
        current_price = closes.iloc[-1]

        # ê³¨ë“ í¬ë¡œìŠ¤ ì—¬ë¶€ (MA5 > MA20 = ë‹¨ê¸° ìƒìŠ¹ ì¶”ì„¸)
        golden_cross = 1 if ma5 > ma20 else 0

        # â”€â”€ ê¸°ìˆ ì  ì§€í‘œ ì ìˆ˜í™” (0~100) â”€â”€
        # RSI: 30 ì´í•˜ = ê³¼ë§¤ë„(ë§¤ìˆ˜ ì‹ í˜¸) â†’ 100ì , 70 ì´ìƒ = ê³¼ë§¤ìˆ˜ â†’ 0ì 
        if rsi < 30:
            rsi_score = 100
        elif rsi > 70:
            rsi_score = 0
        else:
            rsi_score = 100 - (rsi - 30) * (100 / 40)

        # MACD: íˆìŠ¤í† ê·¸ë¨ ì–‘ìˆ˜(ìƒìŠ¹ ëª¨ë©˜í…€) = ë†’ì€ ì ìˆ˜
        macd_score = 100 if macd_hist > 0 else 30

        # MA ì ìˆ˜: ê³¨ë“ í¬ë¡œìŠ¤ + í˜„ì¬ê°€ê°€ MA5 ìœ„ì— ìˆëŠ”ì§€
        ma_score = 70 * golden_cross + 30 * (1 if current_price > ma5 else 0)

        results.append({
            'ì¢…ëª©ì½”ë“œ':   code,
            'RSI':        round(rsi, 2),
            'MACD':       round(macd_val, 2),
            'MACD_Signal':round(macd_signal, 2),
            'MACD_Hist':  round(macd_hist, 2),
            'MA5':        round(ma5, 2),
            'MA20':       round(ma20, 2),
            'ê³¨ë“ í¬ë¡œìŠ¤': golden_cross,
            'RSI_ì ìˆ˜':   round(rsi_score, 1),
            'MACD_ì ìˆ˜':  macd_score,
            'MA_ì ìˆ˜':    ma_score,
            'ê¸°ìˆ ì ìˆ˜':   round((rsi_score * 0.4 + macd_score * 0.35 + ma_score * 0.25), 1),
        })

    tech_df = pd.DataFrame(results)
    if not tech_df.empty:
        logger.info(f"[ê¸°ìˆ ë¶„ì„] {len(tech_df)}ê°œ ì¢…ëª© RSI/MACD/MA ê³„ì‚° ì™„ë£Œ")
    return tech_df


# ============================================================
# [Phase 4] ë‰´ìŠ¤ ê°ì„± ë¶„ì„ (í‚¤ì›Œë“œ ê¸°ë°˜)
# ============================================================
POSITIVE_KEYWORDS = ['ìƒìŠ¹', 'í˜¸ì‹¤ì ', 'ë§¤ìˆ˜', 'ì‹ ê³ ê°€', 'í‘ìì „í™˜', 'ê³„ì•½', 'ìˆ˜ì£¼',
                     'ê¸‰ë“±', 'ì„±ì¥', 'ê°œì„ ', 'ì¦ê°€', 'ëŒíŒŒ', 'ìƒí–¥', 'í˜¸ì¬', 'íšŒë³µ']
NEGATIVE_KEYWORDS = ['í•˜ë½', 'ì ì', 'ë§¤ë„', 'ì†ì‹¤', 'ë¦¬ì½œ', 'ì œì¬', 'ì†Œì†¡',
                     'ê¸‰ë½', 'ê°ì†Œ', 'ë¶€ì§„', 'í•˜í–¥', 'ì•…ì¬', 'ìœ„ê¸°', 'ìš°ë ¤', 'ìµœì €']

def analyze_news_sentiment(news_df, ticker=None):
    """
    ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì˜ ê¸ì •/ë¶€ì • í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ì¢…ëª©ë³„ ê°ì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        news_df: ë‰´ìŠ¤ DataFrame (ì»¬ëŸ¼: ì¢…ëª©ì½”ë“œ, title ë˜ëŠ” ì œëª©)
        ticker: íŠ¹ì • ì¢…ëª©ì½”ë“œ (Noneì´ë©´ ì „ì²´)
    Returns:
        DataFrame: ì¢…ëª©ì½”ë“œë³„ sentiment_score (-100~+100)
    """
    if news_df is None or news_df.empty:
        return pd.DataFrame()

    title_col = 'ì œëª©' if 'ì œëª©' in news_df.columns else 'title'
    code_col  = 'ì¢…ëª©ì½”ë“œ' if 'ì¢…ëª©ì½”ë“œ' in news_df.columns else 'ticker'

    if ticker:
        news_df = news_df[news_df[code_col] == ticker]

    results = []
    for code, group in news_df.groupby(code_col):
        headlines = ' '.join(group[title_col].fillna('').astype(str))
        pos = sum(headlines.count(kw) for kw in POSITIVE_KEYWORDS)
        neg = sum(headlines.count(kw) for kw in NEGATIVE_KEYWORDS)
        total = pos + neg
        if total == 0:
            score = 0.0
        else:
            # -100(ì™„ì „ ë¶€ì •) ~ +100(ì™„ì „ ê¸ì •)
            score = round((pos - neg) / total * 100, 1)

        results.append({
            'ì¢…ëª©ì½”ë“œ':         code,
            'ê¸ì •_í‚¤ì›Œë“œ_ìˆ˜':   pos,
            'ë¶€ì •_í‚¤ì›Œë“œ_ìˆ˜':   neg,
            'sentiment_score':  score,
            'ê°ì„±_ì ìˆ˜':        round((score + 100) / 2, 1),  # 0~100 ë³€í™˜
        })

    sent_df = pd.DataFrame(results)
    if not sent_df.empty:
        logger.info(f"[ê°ì„±ë¶„ì„] {len(sent_df)}ê°œ ì¢…ëª© ë‰´ìŠ¤ ê°ì„± ì ìˆ˜ ì™„ë£Œ")
    return sent_df


def score_stocks(df, investor_type, tech_df=None, sentiment_df=None, analyst_df=None):
    """
    íˆ¬ì ì„±í–¥ì— ë”°ë¼ ì¢…ëª©ë³„ ì¶”ì²œ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        df: í†µí•© ì£¼ì‹ ë°ì´í„° DataFrame
        investor_type: íˆ¬ì ì„±í–¥ (5ë‹¨ê³„ ì¤‘ í•˜ë‚˜)
        tech_df: ê¸°ìˆ ì  ì§€í‘œ DataFrame (calculate_technical_indicators ê²°ê³¼)
        sentiment_df: ê°ì„± ë¶„ì„ DataFrame (analyze_news_sentiment ê²°ê³¼)
        analyst_df: ì¦ê¶Œì‚¬ ëª©í‘œì£¼ê°€ DataFrame (scrape_analyst_opinion ê²°ê³¼)
    Returns:
        DataFrame with 'ì¶”ì²œì ìˆ˜' and 'ì¶”ì²œì´ìœ ' columns added
    """
    if df.empty:
        return df

    result = df.copy()
    weights = WEIGHT_PROFILES.get(investor_type, WEIGHT_PROFILES['ìœ„í—˜ì¤‘ë¦½í˜•'])

    # â”€â”€ ê¸°ìˆ ì  ì§€í‘œ ë³‘í•© â”€â”€
    if tech_df is not None and not tech_df.empty and 'ì¢…ëª©ì½”ë“œ' in result.columns:
        result = result.merge(
            tech_df[['ì¢…ëª©ì½”ë“œ','RSI','MACD_Hist','ê³¨ë“ í¬ë¡œìŠ¤','ê¸°ìˆ ì ìˆ˜']],
            on='ì¢…ëª©ì½”ë“œ', how='left'
        )

    # â”€â”€ ê°ì„± ë¶„ì„ ë³‘í•© â”€â”€
    if sentiment_df is not None and not sentiment_df.empty and 'ì¢…ëª©ì½”ë“œ' in result.columns:
        result = result.merge(
            sentiment_df[['ì¢…ëª©ì½”ë“œ','ê°ì„±_ì ìˆ˜','sentiment_score']],
            on='ì¢…ëª©ì½”ë“œ', how='left'
        )

    # â”€â”€ ì¦ê¶Œì‚¬ ëª©í‘œì£¼ê°€ ë³‘í•© â”€â”€
    if analyst_df is not None and not analyst_df.empty and 'ì¢…ëª©ì½”ë“œ' in result.columns:
        result = result.merge(
            analyst_df[['ì¢…ëª©ì½”ë“œ','ëª©í‘œê°€_ê´´ë¦¬ìœ¨','analyst_score']],
            on='ì¢…ëª©ì½”ë“œ', how='left'
        )

    # â”€â”€ ì§€í‘œë³„ ì ìˆ˜ ê³„ì‚° â”€â”€
    scores = pd.DataFrame(index=result.index)

    # ë°°ë‹¹ìˆ˜ìµë¥  (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
    if 'ë°°ë‹¹ìˆ˜ìµë¥ ' in result.columns:
        scores['ë°°ë‹¹ìˆ˜ìµë¥ '] = _normalize_series(result['ë°°ë‹¹ìˆ˜ìµë¥ '], ascending=True)
    else:
        scores['ë°°ë‹¹ìˆ˜ìµë¥ '] = 0

    # ì‹œê°€ì´ì•¡ ìˆœìœ„ (ëŒ€í˜•ì£¼ = ë†’ì€ ì ìˆ˜)
    if 'ì‹œê°€ì´ì•¡(ì–µ)' in result.columns:
        scores['ì‹œê°€ì´ì•¡_ìˆœìœ„'] = _normalize_series(result['ì‹œê°€ì´ì•¡(ì–µ)'], ascending=True)
    else:
        scores['ì‹œê°€ì´ì•¡_ìˆœìœ„'] = 50

    # ë³€ë™í­ ì—­ìˆœìœ„ (ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì )
    if '52ì£¼ë³€ë™í­(%)' in result.columns:
        scores['ë³€ë™í­_ì—­ìˆœìœ„'] = _normalize_series(result['52ì£¼ë³€ë™í­(%)'], ascending=False)
        scores['ë³€ë™í­_ìˆœìœ„'] = _normalize_series(result['52ì£¼ë³€ë™í­(%)'], ascending=True)
    else:
        scores['ë³€ë™í­_ì—­ìˆœìœ„'] = 50
        scores['ë³€ë™í­_ìˆœìœ„'] = 50

    # PBR ì—­ìˆœìœ„ (ë‚®ì„ìˆ˜ë¡ ì €í‰ê°€)
    if 'PBR' in result.columns:
        scores['PBR_ì—­ìˆœìœ„'] = _normalize_series(result['PBR'], ascending=False)
    else:
        scores['PBR_ì—­ìˆœìœ„'] = 50

    # ê¸°ê´€ ìˆœë§¤ìˆ˜
    if 'ê¸°ê´€_ìˆœë§¤ìˆ˜ëŸ‰' in result.columns:
        scores['ê¸°ê´€_ìˆœë§¤ìˆ˜'] = _normalize_series(result['ê¸°ê´€_ìˆœë§¤ìˆ˜ëŸ‰'], ascending=True)
    else:
        scores['ê¸°ê´€_ìˆœë§¤ìˆ˜'] = 50

    # ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜
    if 'ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜ëŸ‰' in result.columns:
        scores['ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜'] = _normalize_series(result['ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜ëŸ‰'], ascending=True)
    else:
        scores['ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜'] = 50

    # PER ì ì • (10~20 ë²”ìœ„ê°€ ê°€ì¥ ë†’ì€ ì ìˆ˜)
    if 'PER' in result.columns:
        per = pd.to_numeric(result['PER'], errors='coerce').fillna(0)
        scores['PER_ì ì •'] = per.apply(
            lambda x: max(0, 100 - abs(x - 15) * 5) if x > 0 else 0
        )
    else:
        scores['PER_ì ì •'] = 50

    # ê±°ë˜ëŸ‰ ìˆœìœ„ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
    if 'ê±°ë˜ëŸ‰' in result.columns:
        scores['ê±°ë˜ëŸ‰_ìˆœìœ„'] = _normalize_series(result['ê±°ë˜ëŸ‰'], ascending=True)
    else:
        scores['ê±°ë˜ëŸ‰_ìˆœìœ„'] = 50

    # ë“±ë½ë¥  ì ˆëŒ€ê°’ (ë†’ì„ìˆ˜ë¡ ë³€ë™ì„± í¼)
    if 'ë“±ë½ë¥ (ìˆ«ì)' in result.columns:
        scores['ë“±ë½ë¥ _ì ˆëŒ€ê°’'] = _normalize_series(
            result['ë“±ë½ë¥ (ìˆ«ì)'].abs(), ascending=True
        )
    elif 'ë“±ë½ë¥ ' in result.columns:
        from scraper import parse_change_pct
        pct_values = result['ë“±ë½ë¥ '].apply(parse_change_pct).abs()
        scores['ë“±ë½ë¥ _ì ˆëŒ€ê°’'] = _normalize_series(pct_values, ascending=True)
    else:
        scores['ë“±ë½ë¥ _ì ˆëŒ€ê°’'] = 50

    # [Phase 1] ê¸°ìˆ ì  ì§€í‘œ ì ìˆ˜
    if 'ê¸°ìˆ ì ìˆ˜' in result.columns:
        scores['ê¸°ìˆ ì ìˆ˜'] = result['ê¸°ìˆ ì ìˆ˜'].fillna(50)
    else:
        scores['ê¸°ìˆ ì ìˆ˜'] = 50

    # [Phase 4] ë‰´ìŠ¤ ê°ì„± ì ìˆ˜
    if 'ê°ì„±_ì ìˆ˜' in result.columns:
        scores['ê°ì„±_ì ìˆ˜'] = result['ê°ì„±_ì ìˆ˜'].fillna(50)
    else:
        scores['ê°ì„±_ì ìˆ˜'] = 50

    # [Phase 3] ì¦ê¶Œì‚¬ ëª©í‘œì£¼ê°€ ì ìˆ˜
    if 'analyst_score' in result.columns:
        scores['analyst_score'] = result['analyst_score'].fillna(50)
    else:
        scores['analyst_score'] = 50

    # â”€â”€ ê°€ì¤‘ì¹˜ ì ìš© ì´ì  ê³„ì‚° â”€â”€
    total = pd.Series(0.0, index=result.index)
    for metric, weight in weights.items():
        if metric in scores.columns:
            total += scores[metric] * weight

    result['ì¶”ì²œì ìˆ˜'] = total.round(2)

    # â”€â”€ ì¶”ì²œ ì´ìœ  ìƒì„± â”€â”€
    def make_reason(idx):
        parts = []
        score_data = scores.loc[idx]
        top_metrics = sorted(weights.items(), key=lambda x: x[1], reverse=True)[:3]

        for metric, weight in top_metrics:
            if metric in score_data.index:
                val = score_data[metric]
                if val >= 70:
                    metric_names = {
                        'ë°°ë‹¹ìˆ˜ìµë¥ ':   'ë†’ì€ ë°°ë‹¹ìˆ˜ìµë¥ ',
                        'ì‹œê°€ì´ì•¡_ìˆœìœ„':'ëŒ€í˜• ìš°ëŸ‰ì£¼',
                        'ë³€ë™í­_ì—­ìˆœìœ„':'ë‚®ì€ ë³€ë™ì„±',
                        'ë³€ë™í­_ìˆœìœ„':  'ë†’ì€ ë³€ë™ì„±(ê¸°íšŒ)',
                        'PBR_ì—­ìˆœìœ„':   'ì €í‰ê°€(PBR)',
                        'ê¸°ê´€_ìˆœë§¤ìˆ˜':  'ê¸°ê´€ ìˆœë§¤ìˆ˜ ì–‘í˜¸',
                        'ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜':'ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì–‘í˜¸',
                        'PER_ì ì •':     'ì ì • PER',
                        'ê±°ë˜ëŸ‰_ìˆœìœ„':  'ë†’ì€ ê±°ë˜ëŸ‰',
                        'ë“±ë½ë¥ _ì ˆëŒ€ê°’':'ë†’ì€ ë“±ë½ë¥ ',
                        'ê¸°ìˆ ì ìˆ˜':     'ê¸°ìˆ ì  ë§¤ìˆ˜ ì‹ í˜¸',
                        'ê°ì„±_ì ìˆ˜':    'ê¸ì •ì  ë‰´ìŠ¤ ê°ì„±',
                        'analyst_score':'ì¦ê¶Œì‚¬ ëª©í‘œì£¼ê°€ ìƒí–¥',
                    }
                    parts.append(metric_names.get(metric, metric))

        return ' + '.join(parts) if parts else 'ì¢…í•© ë¶„ì„ ì¶”ì²œ'

    result['ì¶”ì²œì´ìœ '] = [make_reason(result.index[i]) for i in range(len(result))]
    result = result.sort_values('ì¶”ì²œì ìˆ˜', ascending=False).reset_index(drop=True)

    logger.info(f"[ìŠ¤ì½”ì–´ë§] {investor_type} ê¸°ì¤€ {len(result)}ê°œ ì¢…ëª© ì ìˆ˜ ê³„ì‚° ì™„ë£Œ")
    return result


def get_top_recommendations(df, investor_type, top_n=10):
    """
    íˆ¬ì ì„±í–¥ì— ë§ëŠ” ìƒìœ„ Nê°œ ì¢…ëª©ì„ ì¶”ì²œí•©ë‹ˆë‹¤.

    Args:
        df: í†µí•© ì£¼ì‹ ë°ì´í„° DataFrame
        investor_type: íˆ¬ì ì„±í–¥
        top_n: ì¶”ì²œ ì¢…ëª© ìˆ˜
    Returns:
        DataFrame - ì¶”ì²œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
    """
    scored_df = score_stocks(df, investor_type)
    result = scored_df.head(top_n)
    logger.info(f"[ì¶”ì²œ] {investor_type} ì„±í–¥ ìƒìœ„ {len(result)}ê°œ ì¢…ëª© ì¶”ì²œ ìƒì„±")
    return result


# ============================================================
# 4. ì‹œì¥ ë¶„ì„ ìš”ì•½
# ============================================================
def generate_analysis_summary(df):
    """
    ì „ì²´ ì‹œì¥ ë°ì´í„°ì— ëŒ€í•œ ìš”ì•½ í†µê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        df: í†µí•© ì£¼ì‹ ë°ì´í„° DataFrame
    Returns:
        dict - ìš”ì•½ í†µê³„
    """
    summary = {
        'ì´ ì¢…ëª© ìˆ˜': len(df),
        'ìˆ˜ì§‘ ì‹œê°„': df['ìˆ˜ì§‘ì‹œê°„'].iloc[0] if 'ìˆ˜ì§‘ì‹œê°„' in df.columns and len(df) > 0 else 'N/A',
    }

    if 'KOSPI' in df['ì‹œì¥'].values:
        kospi = df[df['ì‹œì¥'] == 'KOSPI']
        summary['KOSPI ì¢…ëª© ìˆ˜'] = len(kospi)
    if 'KOSDAQ' in df['ì‹œì¥'].values:
        kosdaq = df[df['ì‹œì¥'] == 'KOSDAQ']
        summary['KOSDAQ ì¢…ëª© ìˆ˜'] = len(kosdaq)

    # ë“±ë½ í†µê³„
    pct = None
    if 'ë“±ë½ë¥ (ìˆ«ì)' in df.columns:
        pct = pd.to_numeric(df['ë“±ë½ë¥ (ìˆ«ì)'], errors='coerce')
    elif 'ë“±ë½ë¥ ' in df.columns:
        from scraper import parse_change_pct
        pct = df['ë“±ë½ë¥ '].apply(parse_change_pct)

    if pct is not None:
        summary['ìƒìŠ¹ ì¢…ëª© ìˆ˜'] = int((pct > 0).sum())
        summary['í•˜ë½ ì¢…ëª© ìˆ˜'] = int((pct < 0).sum())
        summary['ë³´í•© ì¢…ëª© ìˆ˜'] = int((pct == 0).sum())
        summary['í‰ê·  ë“±ë½ë¥ (%)'] = round(pct.mean(), 2)

    # ê±°ë˜ëŸ‰ í†µê³„
    if 'ê±°ë˜ëŸ‰' in df.columns:
        vol = pd.to_numeric(df['ê±°ë˜ëŸ‰'], errors='coerce')
        summary['í‰ê·  ê±°ë˜ëŸ‰'] = f"{int(vol.mean()):,}"
        summary['ìµœëŒ€ ê±°ë˜ëŸ‰ ì¢…ëª©'] = df.loc[vol.idxmax(), 'ì¢…ëª©ëª…'] if not vol.empty else 'N/A'

    # ì™¸êµ­ì¸/ê¸°ê´€ í†µê³„
    if 'ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜ëŸ‰' in df.columns:
        foreign = pd.to_numeric(df['ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜ëŸ‰'], errors='coerce')
        summary['ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì¢…ëª©'] = int((foreign > 0).sum())
        summary['ì™¸êµ­ì¸ ìˆœë§¤ë„ ì¢…ëª©'] = int((foreign < 0).sum())

    if 'ê¸°ê´€_ìˆœë§¤ìˆ˜ëŸ‰' in df.columns:
        inst = pd.to_numeric(df['ê¸°ê´€_ìˆœë§¤ìˆ˜ëŸ‰'], errors='coerce')
        summary['ê¸°ê´€ ìˆœë§¤ìˆ˜ ì¢…ëª©'] = int((inst > 0).sum())
        summary['ê¸°ê´€ ìˆœë§¤ë„ ì¢…ëª©'] = int((inst < 0).sum())

    return summary


# ============================================================
# 5. (E) analysis_signals â€” ë¶„ì„ ì‹ í˜¸ ìƒì„±
#    DB ìŠ¤í‚¤ë§ˆ: ticker, as_of, window, trend_score, signal
# ============================================================
def generate_analysis_signals(df, window='1D'):
    """
    ì¢…ëª©ë³„ ì¶”ì„¸ ì ìˆ˜ì™€ BUY/HOLD/SELL ì‹ í˜¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ì¶”ì„¸ ì ìˆ˜ ì‚°ì¶œ ë¡œì§:
      â‘  ë“±ë½ë¥  ì ìˆ˜   (ê°€ì¤‘ì¹˜ 40%) : ìƒìŠ¹ â†’ +, í•˜ë½ â†’ -
      â‘¡ ê±°ë˜ëŸ‰ ì ìˆ˜   (ê°€ì¤‘ì¹˜ 20%) : í‰ê·  ëŒ€ë¹„ ë¹„ìœ¨
      â‘¢ ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ (ê°€ì¤‘ì¹˜ 20%) : ì–‘(+) â†’ ë§¤ìˆ˜ ì‹ í˜¸
      â‘£ ê¸°ê´€ ìˆœë§¤ìˆ˜   (ê°€ì¤‘ì¹˜ 20%) : ì–‘(+) â†’ ë§¤ìˆ˜ ì‹ í˜¸

    signal íŒì •:
      trend_score >= 60  â†’ BUY
      trend_score >= 40  â†’ HOLD
      trend_score <  40  â†’ SELL

    Args:
        df: í†µí•© ì£¼ì‹ ë°ì´í„° DataFrame
        window: ë¶„ì„ ê¸°ê°„ ë¼ë²¨ ('1D', '1W', '1M')
    Returns:
        DataFrame â€” analysis_signals í…Œì´ë¸” í˜•ì‹
    """
    if df.empty:
        return pd.DataFrame()

    records = []
    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    # ì •ê·œí™”ë¥¼ ìœ„í•œ ì „ì²´ í†µê³„
    vol_mean = pd.to_numeric(df.get('ê±°ë˜ëŸ‰', pd.Series(dtype=float)),
                             errors='coerce').mean()
    if pd.isna(vol_mean) or vol_mean == 0:
        vol_mean = 1

    for _, row in df.iterrows():
        # â”€â”€ â‘  ë“±ë½ë¥  ì ìˆ˜ (0~100) â”€â”€
        pct = 0.0
        if 'ë“±ë½ë¥ (ìˆ«ì)' in df.columns:
            pct = pd.to_numeric(row.get('ë“±ë½ë¥ (ìˆ«ì)', 0), errors='coerce')
        elif 'ë“±ë½ë¥ ' in df.columns:
            from scraper import parse_change_pct
            pct = parse_change_pct(str(row.get('ë“±ë½ë¥ ', '0')))
        if pd.isna(pct):
            pct = 0.0
        # ë“±ë½ë¥ ì„ 0~100 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ (-30% â†’ 0, 0% â†’ 50, +30% â†’ 100)
        pct_score = max(0, min(100, 50 + pct * (50 / 30)))

        # â”€â”€ â‘¡ ê±°ë˜ëŸ‰ ì ìˆ˜ (0~100) â”€â”€
        vol = pd.to_numeric(row.get('ê±°ë˜ëŸ‰', 0), errors='coerce')
        if pd.isna(vol):
            vol = 0
        vol_ratio = vol / vol_mean
        vol_score = max(0, min(100, vol_ratio * 50))

        # â”€â”€ â‘¢ ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì ìˆ˜ (0~100) â”€â”€
        foreign = pd.to_numeric(row.get('ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜ëŸ‰', 0), errors='coerce')
        if pd.isna(foreign):
            foreign = 0
        foreign_score = 50 + (50 if foreign > 0 else -30 if foreign < 0 else 0)
        foreign_score = max(0, min(100, foreign_score))

        # â”€â”€ â‘£ ê¸°ê´€ ìˆœë§¤ìˆ˜ ì ìˆ˜ (0~100) â”€â”€
        inst = pd.to_numeric(row.get('ê¸°ê´€_ìˆœë§¤ìˆ˜ëŸ‰', 0), errors='coerce')
        if pd.isna(inst):
            inst = 0
        inst_score = 50 + (50 if inst > 0 else -30 if inst < 0 else 0)
        inst_score = max(0, min(100, inst_score))

        # â”€â”€ ê°€ì¤‘ í‰ê·  ì¶”ì„¸ ì ìˆ˜ â”€â”€
        trend_score = round(
            pct_score * 0.40 +
            vol_score * 0.20 +
            foreign_score * 0.20 +
            inst_score * 0.20,
            2
        )

        # â”€â”€ ì‹ í˜¸ íŒì • â”€â”€
        if trend_score >= 60:
            signal = 'BUY'
        elif trend_score >= 40:
            signal = 'HOLD'
        else:
            signal = 'SELL'

        records.append({
            'ticker': row.get('ì¢…ëª©ì½”ë“œ', ''),
            'as_of': now,
            'window': window,
            'trend_score': trend_score,
            'signal': signal,
        })

    signals_df = pd.DataFrame(records)
    logger.info(f"[ë¶„ì„ ì‹ í˜¸] {len(signals_df)}ê°œ ì¢…ëª© {window} ì‹ í˜¸ ìƒì„± ì™„ë£Œ "
                f"(BUY:{(signals_df['signal']=='BUY').sum()}, "
                f"HOLD:{(signals_df['signal']=='HOLD').sum()}, "
                f"SELL:{(signals_df['signal']=='SELL').sum()})")
    return signals_df


# ============================================================
# 6. (F) recommendations â€” DB í˜•ì‹ ì¶”ì²œ ë°ì´í„° ìƒì„±
#    DB ìŠ¤í‚¤ë§ˆ: user_id, ticker, as_of, score, reason
# ============================================================
def build_recommendations_df(scored_df, user_id=1, top_n=10):
    """
    ìŠ¤ì½”ì–´ë§ëœ DataFrameì„ recommendations í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        scored_df: score_stocks() ê²°ê³¼ DataFrame (ì¶”ì²œì ìˆ˜, ì¶”ì²œì´ìœ  í¬í•¨)
        user_id: ì‚¬ìš©ì ID (ê¸°ë³¸ê°’: 1)
        top_n: ì¶”ì²œ ì¢…ëª© ìˆ˜
    Returns:
        DataFrame â€” recommendations í…Œì´ë¸” í˜•ì‹
    """
    if scored_df.empty:
        return pd.DataFrame()

    top = scored_df.head(top_n)
    today = datetime.now().strftime('%Y-%m-%d')

    recs = pd.DataFrame({
        'user_id': user_id,
        'ticker': top['ì¢…ëª©ì½”ë“œ'].values,
        'as_of': today,
        'score': top['ì¶”ì²œì ìˆ˜'].values,
        'reason': top['ì¶”ì²œì´ìœ '].values,
    })

    logger.info(f"[ì¶”ì²œ DB] user_id={user_id}, {len(recs)}ê±´ ì¶”ì²œ ë°ì´í„° ìƒì„±")
    return recs


# ============================================================
# 7. (G) newsletters â€” ë‰´ìŠ¤ë ˆí„° ìƒì„±
#    DB ìŠ¤í‚¤ë§ˆ: user_id, created_at, title, content
# ============================================================
def generate_newsletter(stock_df, scored_df, signals_df, investor_type,
                        user_id=1, news_df=None):
    """
    íˆ¬ì ì„±í–¥ë³„ ë§ì¶¤ ë‰´ìŠ¤ë ˆí„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        stock_df: ì „ì²´ ì£¼ì‹ ë°ì´í„° DataFrame
        scored_df: ìŠ¤ì½”ì–´ë§ëœ ì¶”ì²œ DataFrame
        signals_df: ë¶„ì„ ì‹ í˜¸ DataFrame
        investor_type: íˆ¬ì ì„±í–¥ (5ë‹¨ê³„)
        user_id: ì‚¬ìš©ì ID
        news_df: ë‰´ìŠ¤ DataFrame (ì„ íƒ)
    Returns:
        dict â€” newsletters í…Œì´ë¸” í˜•ì‹
    """
    now = datetime.now()
    type_info = TYPE_DESCRIPTIONS.get(investor_type, TYPE_DESCRIPTIONS['ìœ„í—˜ì¤‘ë¦½í˜•'])
    summary = generate_analysis_summary(stock_df)

    # â”€â”€ ì œëª© â”€â”€
    title = f"[{now.strftime('%Y-%m-%d')}] {type_info['emoji']} {investor_type} ë§ì¶¤ íˆ¬ì ë‰´ìŠ¤ë ˆí„°"

    # â”€â”€ ë³¸ë¬¸ êµ¬ì„± â”€â”€
    lines = []
    lines.append(f"{'='*50}")
    lines.append(f"ğŸ“Š {investor_type} íˆ¬ììë¥¼ ìœ„í•œ ì¼ì¼ ë‰´ìŠ¤ë ˆí„°")
    lines.append(f"ğŸ“… {now.strftime('%Yë…„ %mì›” %dì¼ %H:%M')}")
    lines.append(f"{'='*50}")
    lines.append("")

    # ì‹œì¥ ê°œìš”
    lines.append("â–  ì‹œì¥ ê°œìš”")
    lines.append(f"  - ë¶„ì„ ì¢…ëª© ìˆ˜: {summary.get('ì´ ì¢…ëª© ìˆ˜', 0)}ê°œ")
    if 'ìƒìŠ¹ ì¢…ëª© ìˆ˜' in summary:
        lines.append(f"  - ìƒìŠ¹: {summary['ìƒìŠ¹ ì¢…ëª© ìˆ˜']}ê°œ | "
                     f"í•˜ë½: {summary['í•˜ë½ ì¢…ëª© ìˆ˜']}ê°œ | "
                     f"ë³´í•©: {summary.get('ë³´í•© ì¢…ëª© ìˆ˜', 0)}ê°œ")
    if 'í‰ê·  ë“±ë½ë¥ (%)' in summary:
        lines.append(f"  - í‰ê·  ë“±ë½ë¥ : {summary['í‰ê·  ë“±ë½ë¥ (%)']}%")
    lines.append("")

    # ë¶„ì„ ì‹ í˜¸ ìš”ì•½
    if not signals_df.empty:
        buy_cnt = (signals_df['signal'] == 'BUY').sum()
        hold_cnt = (signals_df['signal'] == 'HOLD').sum()
        sell_cnt = (signals_df['signal'] == 'SELL').sum()
        lines.append("â–  ë¶„ì„ ì‹ í˜¸ ìš”ì•½")
        lines.append(f"  - ğŸŸ¢ ë§¤ìˆ˜(BUY): {buy_cnt}ê°œ")
        lines.append(f"  - ğŸŸ¡ ë³´ìœ (HOLD): {hold_cnt}ê°œ")
        lines.append(f"  - ğŸ”´ ë§¤ë„(SELL): {sell_cnt}ê°œ")
        lines.append("")

    # ì¶”ì²œ ì¢…ëª© TOP 5
    lines.append(f"â–  {type_info['emoji']} {investor_type} ì¶”ì²œ ì¢…ëª© TOP 5")
    lines.append(f"  ì „ëµ: {type_info['strategy']}")
    lines.append("")

    top5 = scored_df.head(5)
    for i, (_, row) in enumerate(top5.iterrows(), 1):
        name = row.get('ì¢…ëª©ëª…', row.get('ì¢…ëª©ì½”ë“œ', ''))
        price = row.get('í˜„ì¬ê°€', 0)
        pct = row.get('ë“±ë½ë¥ ', 'N/A')
        score = row.get('ì¶”ì²œì ìˆ˜', 0)
        reason = row.get('ì¶”ì²œì´ìœ ', '')
        lines.append(f"  {i}. {name}")
        lines.append(f"     í˜„ì¬ê°€: {price:,}ì› ({pct})")
        lines.append(f"     ì¶”ì²œì ìˆ˜: {score:.1f}ì  | ì‚¬ìœ : {reason}")

        # í•´ë‹¹ ì¢…ëª©ì˜ ë¶„ì„ ì‹ í˜¸
        if not signals_df.empty and 'ì¢…ëª©ì½”ë“œ' in row.index:
            sig_row = signals_df[signals_df['ticker'] == row['ì¢…ëª©ì½”ë“œ']]
            if not sig_row.empty:
                sig = sig_row.iloc[0]
                lines.append(f"     ë¶„ì„ì‹ í˜¸: {sig['signal']} "
                             f"(ì¶”ì„¸ì ìˆ˜: {sig['trend_score']})")
        lines.append("")

    # ê´€ë ¨ ë‰´ìŠ¤
    if news_df is not None and not news_df.empty:
        lines.append("â–  ê´€ë ¨ ë‰´ìŠ¤")
        top_tickers = top5['ì¢…ëª©ì½”ë“œ'].tolist() if 'ì¢…ëª©ì½”ë“œ' in top5.columns else []
        relevant_news = news_df[news_df['ì¢…ëª©ì½”ë“œ'].isin(top_tickers)] if top_tickers else news_df
        for _, nrow in relevant_news.head(5).iterrows():
            stock_name = nrow.get('ì¢…ëª©ëª…', nrow.get('ì¢…ëª©ì½”ë“œ', ''))
            news_title = nrow.get('ë‰´ìŠ¤ì œëª©', '')
            lines.append(f"  ğŸ“° [{stock_name}] {news_title}")
        lines.append("")

    lines.append(f"{'='*50}")
    lines.append("â€» ë³¸ ë‰´ìŠ¤ë ˆí„°ëŠ” íˆ¬ì ì°¸ê³ ìš©ì´ë©°, íˆ¬ì íŒë‹¨ì˜ ì±…ì„ì€ íˆ¬ììì—ê²Œ ìˆìŠµë‹ˆë‹¤.")

    content = '\n'.join(lines)

    newsletter = {
        'user_id': user_id,
        'created_at': now.strftime('%Y-%m-%d %H:%M:%S'),
        'title': title,
        'content': content,
    }

    logger.info(f"[ë‰´ìŠ¤ë ˆí„°] user_id={user_id}, '{title}' ìƒì„± ì™„ë£Œ")
    return newsletter
