# ğŸ“‹ ì£¼ì‹ ì¶”ì²œ ì‹œìŠ¤í…œ â€” ì£¼ìš” ì½”ë“œ ì„¤ëª… ë³´ê³ ì„œ

> í‰ê°€ í•­ëª©ë³„ ì£¼ìš” ì½”ë“œ ë¶„ì„ ë° ì„¤ëª…ì„œ
> **1íŒ€ | 2026-02-24**

---

## 1. í”„ë¡œì íŠ¸ ê¸°íš ë° ì£¼ì œ ì ì ˆì„± _(10ì )_

### 1-1. ì£¼ì œ ì„ ì • ë°°ê²½ ë° ë¬¸ì œ ì •ì˜

ì£¼ì‹ íˆ¬ì ì…ë¬¸ìëŠ” **"ì–´ë–¤ ì¢…ëª©ì„ ì–¸ì œ ì‚¬ì•¼ í•˜ëŠ”ê°€"** ë¼ëŠ” ì •ë³´ ë¶ˆê· í˜• ë¬¸ì œì— ìì£¼ ì§ë©´í•©ë‹ˆë‹¤.  
ë³¸ í”„ë¡œì íŠ¸ëŠ” ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì•„ë˜ 3ê°€ì§€ í•µì‹¬ ëª©í‘œë¥¼ ì„¤ì •í•˜ì˜€ìŠµë‹ˆë‹¤.

| ë¬¸ì œ | í•´ê²° ì ‘ê·¼ |
|------|-----------|
| ì¢‹ì€ ì¢…ëª©ì„ ì–´ë–»ê²Œ ê³ ë¥´ë‚˜? | ê±°ë˜ëŸ‰Â·ì™¸êµ­ì¸/ê¸°ê´€ ë§¤ë§¤ ë°ì´í„° ê¸°ë°˜ ì‹ í˜¸ ë¶„ì„ |
| ë‚´ ì„±í–¥ì— ë§ì§€ ì•ŠëŠ” ì¶”ì²œ | í•œì–‘ì¦ê¶Œ ê¸°ì¤€ 11ë¬¸í•­ íˆ¬ì ì„±í–¥ ì§„ë‹¨ |
| ì •ë³´ íšë“ì˜ ì§„ì… ì¥ë²½ | Streamlit ê¸°ë°˜ ì‹œê°í™” ëŒ€ì‹œë³´ë“œ ì œê³µ |

### 1-2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
[ë°ì´í„° ìˆ˜ì§‘]       [ë¶„ì„/ì²˜ë¦¬]         [ì„œë¹„ìŠ¤]
scraper.py  â”€â”€â–¶  analyzer.py  â”€â”€â–¶   app.py (Streamlit)
scheduler   â”€â”€â–¶  rtd_analyzer â”€â”€â–¶   ì‹¤ì‹œê°„ RTD ì°¨íŠ¸
                 db_manager   â”€â”€â–¶   MySQL / CSV
```

---

## 2. ë°ì´í„° ìˆ˜ì§‘ ë° ì •ì œ _(25ì )_

### 2-1. `requests` + `BeautifulSoup` â€” ê±°ë˜ëŸ‰ ìƒìœ„ ì¢…ëª© ìˆ˜ì§‘

ë„¤ì´ë²„ ê¸ˆìœµ `sise_quant.naver` í˜ì´ì§€ì—ì„œ KOSPI/KOSDAQ ìƒìœ„ 100ì¢…ëª© ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

```python
# scraper.py - scrape_top_volume() í•¨ìˆ˜

def create_session(retries=3, backoff=0.5):
    """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ requests.Session ìƒì„±"""
    session = requests.Session()
    retry_strategy = Retry(
        total=retries,
        backoff_factor=backoff,
        status_forcelist=[429, 500, 502, 503, 504],  # ì„œë²„ ì˜¤ë¥˜ ì‹œ ìë™ ì¬ì‹œë„
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.headers.update(HEADERS)  # User-Agent í—¤ë” ìœ„ì¥
    return session

def scrape_top_volume(market="KOSPI", limit=100, session=None):
    sosok = "0" if market == "KOSPI" else "1"
    url = f"https://finance.naver.com/sise/sise_quant.naver?sosok={sosok}&page={page}"

    resp = session.get(url, timeout=10)
    resp.encoding = 'euc-kr'                          # í•œê¸€ ì¸ì½”ë”© ì²˜ë¦¬
    soup = BeautifulSoup(resp.text, 'html.parser')

    rows = soup.select('table.type_2 tr')             # CSS ì…€ë ‰í„°ë¡œ í…Œì´ë¸” íŒŒì‹±
    for row in rows:
        cols = row.select('td')
        name  = cols[1].text.strip()
        code  = cols[1].find('a')['href'].split('code=')[-1]
        price = clean_number(cols[2].text)             # ìˆ«ì ì •ì œ í•¨ìˆ˜ ì ìš©
```

**í•µì‹¬ í¬ì¸íŠ¸:**
- `Retry` ê°ì²´ë¡œ ì„œë²„ ë¶ˆì•ˆì • ì‹œ ìë™ ì¬ì‹œë„ (ìµœëŒ€ 3íšŒ)
- `euc-kr` ì¸ì½”ë”© ì²˜ë¦¬ë¡œ í•œê¸€ ê¹¨ì§ ë°©ì§€
- CSS ì…€ë ‰í„°(`table.type_2 tr`)ë¡œ ì •í™•í•œ ë°ì´í„° ìœ„ì¹˜ ì¶”ì¶œ

---

### 2-2. ë°ì´í„° ì •ì œ í•¨ìˆ˜

```python
# scraper.py - ë°ì´í„° ì •ì œ ìœ í‹¸ë¦¬í‹°

def clean_number(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ìë¥¼ ì¶”ì¶œí•˜ì—¬ ì •ìˆ˜ë¡œ ë³€í™˜ (ìŒìˆ˜ ì§€ì›)"""
    text = str(text).strip()
    is_negative = text.startswith('-') or 'â–¼' in text  # í•˜ë½ ê¸°í˜¸ ê°ì§€
    nums = re.sub(r'[^\d]', '', text)                  # ìˆ«ì ì™¸ ë¬¸ì ì œê±°
    result = int(nums) if nums else 0
    return -result if is_negative else result

def clean_float(text):
    """ì‹¤ìˆ˜(ì†Œìˆ˜ì ) ì¶”ì¶œ"""
    text = text.strip().replace(',', '')
    match = re.search(r'[-+]?\d+\.?\d*', text)
    return float(match.group()) if match else None

def parse_change_pct(pct_text):
    """'+2.35%' â†’ 2.35, '-1.05%' â†’ -1.05 ë³€í™˜"""
    pct_text = pct_text.strip().replace('%', '')
    return float(pct_text)
```

---

### 2-3. `Selenium` â€” ì™¸êµ­ì¸/ê¸°ê´€ ë§¤ë§¤ ë™í–¥ ìˆ˜ì§‘

ë™ì  ë Œë”ë§ì´ í•„ìš”í•œ í˜ì´ì§€ëŠ” Seleniumìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

```python
# scraper.py - get_investor_trading() í•¨ìˆ˜

def get_driver():
    """Headless Chrome ë“œë¼ì´ë²„ ì„¤ì •"""
    options = Options()
    options.add_argument('--headless')         # í™”ë©´ ì—†ì´ ì‹¤í–‰
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    return webdriver.Chrome(options=options)

def scrape_news_selenium(ticker, name, driver=None):
    """ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ (JavaScript ë Œë”ë§ í•„ìš”)"""
    url = f"https://finance.naver.com/item/news_news.naver?code={ticker}"
    driver.get(url)
    # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
    WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, 'table.type5'))
    )
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    rows = soup.select('table.type5 tr')
```

---

### 2-4. `pykrx` â€” ê³¼ê±° ì‹œì„¸ ë°ì´í„° (API í˜¸ì¶œ)

ë„¤ì´ë²„ ìŠ¤í¬ë˜í•‘ ëŒ€ì‹  pykrx APIë¡œ ì •í™•í•œ OHLCV ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

```python
# scraper.py - scrape_historical_data() í•¨ìˆ˜

from pykrx import stock

def scrape_historical_data(tickers, days=7):
    """
    pykrx APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¢…ëª©ì˜ ê³¼ê±° ì‹œì„¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    pykrxëŠ” í•œêµ­ê±°ë˜ì†Œ(KRX) ê³µì‹ ë°ì´í„°ë¥¼ API í˜•íƒœë¡œ ì œê³µí•©ë‹ˆë‹¤.
    """
    end = datetime.today().strftime('%Y%m%d')
    start = (datetime.today() - timedelta(days=days)).strftime('%Y%m%d')

    dfs = []
    for ticker in tickers:
        df = stock.get_market_ohlcv(start, end, ticker)  # OHLCV ìˆ˜ì§‘
        df['ì¢…ëª©ì½”ë“œ'] = ticker
        dfs.append(df)

    return pd.concat(dfs).reset_index()  # ë‚ ì§œ ì¸ë±ìŠ¤ â†’ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
```

---

### 2-5. ë°ì´í„° êµ¬ì¡°í™” ê²°ê³¼ (`pandas DataFrame`)

| ì»¬ëŸ¼ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `ì¢…ëª©ì½”ë“œ` | str | 6ìë¦¬ KRX ì¢…ëª©ì½”ë“œ |
| `ì¢…ëª©ëª…` | str | ì¢…ëª© ì´ë¦„ |
| `ì‹œì¥` | str | KOSPI / KOSDAQ |
| `í˜„ì¬ê°€` | int | í˜„ì¬ ì£¼ê°€ (ì›) |
| `ë“±ë½ë¥ ` | str | ì „ì¼ ëŒ€ë¹„ ë“±ë½ë¥  |
| `ê±°ë˜ëŸ‰` | int | ë‹¹ì¼ ëˆ„ì  ê±°ë˜ëŸ‰ |
| `ê±°ë˜ëŒ€ê¸ˆ` | int | ë‹¹ì¼ ì´ ê±°ë˜ê¸ˆì•¡ (ë°±ë§Œì›) |
| `ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜ëŸ‰` | int | ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ìˆ˜ëŸ‰ |
| `ê¸°ê´€_ìˆœë§¤ìˆ˜ëŸ‰` | int | ê¸°ê´€ ìˆœë§¤ìˆ˜ ìˆ˜ëŸ‰ |

---

## 3. ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” _(30ì )_

### 3-1. `pandas` â€” ì£¼ì‹ ë°ì´í„° ë¶„ì„

#### (1) ì¶”ì„¸ ì ìˆ˜(trend_score) ì‚°ì¶œ

```python
# analyzer.py - generate_analysis_signals() í•¨ìˆ˜

def generate_analysis_signals(df, window='1D'):
    """
    ë“±ë½ë¥ , ê±°ë˜ëŸ‰, ì™¸êµ­ì¸/ê¸°ê´€ ë§¤ë§¤ë¥¼ ê°€ì¤‘ í•©ì‚°í•˜ì—¬
    0~100 ìŠ¤ì¼€ì¼ì˜ ì¶”ì„¸ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    result = df.copy()

    # 1) ë“±ë½ë¥  ì ìˆ˜ (40% ê°€ì¤‘ì¹˜)
    pct_col = 'ë“±ë½ë¥ (ìˆ«ì)' if 'ë“±ë½ë¥ (ìˆ«ì)' in df.columns else 'ë“±ë½ë¥ _num'
    result['ë“±ë½ì ìˆ˜'] = _normalize_series(
        pd.to_numeric(df[pct_col], errors='coerce'), ascending=True
    )  # 0~100 ì •ê·œí™”

    # 2) ê±°ë˜ëŸ‰ ì ìˆ˜ (20% ê°€ì¤‘ì¹˜)
    result['ê±°ë˜ëŸ‰ì ìˆ˜'] = _normalize_series(df['ê±°ë˜ëŸ‰'], ascending=True)

    # 3) ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì ìˆ˜ (20% ê°€ì¤‘ì¹˜)
    if 'ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜ëŸ‰' in df.columns:
        result['ì™¸êµ­ì¸ì ìˆ˜'] = _normalize_series(df['ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜ëŸ‰'], ascending=True)
    else:
        result['ì™¸êµ­ì¸ì ìˆ˜'] = 50  # ë°ì´í„° ì—†ìœ¼ë©´ ì¤‘ë¦½ê°’

    # 4) ê¸°ê´€ ìˆœë§¤ìˆ˜ ì ìˆ˜ (20% ê°€ì¤‘ì¹˜)
    if 'ê¸°ê´€_ìˆœë§¤ìˆ˜ëŸ‰' in df.columns:
        result['ê¸°ê´€ì ìˆ˜'] = _normalize_series(df['ê¸°ê´€_ìˆœë§¤ìˆ˜ëŸ‰'], ascending=True)
    else:
        result['ê¸°ê´€ì ìˆ˜'] = 50

    # 5) ìµœì¢… ê°€ì¤‘ í•©ì‚°
    result['trend_score'] = (
        result['ë“±ë½ì ìˆ˜']   * 0.40 +
        result['ê±°ë˜ëŸ‰ì ìˆ˜'] * 0.20 +
        result['ì™¸êµ­ì¸ì ìˆ˜'] * 0.20 +
        result['ê¸°ê´€ì ìˆ˜']   * 0.20
    ).round(1)

    # 6) BUY / HOLD / SELL ë¶„ë¥˜
    result['signal'] = result['trend_score'].apply(
        lambda s: 'BUY' if s >= 60 else ('SELL' if s < 40 else 'HOLD')
    )
    return result
```

#### (2) íˆ¬ì ì„±í–¥ë³„ ì¢…ëª© ìŠ¤ì½”ì–´ë§

```python
# analyzer.py - score_stocks() í•¨ìˆ˜

WEIGHT_PROFILES = {
    'ì•ˆì •í˜•':    {'ë°°ë‹¹ìˆ˜ìµë¥ ': 0.30, 'ì‹œê°€ì´ì•¡_ìˆœìœ„': 0.25, 'ë³€ë™í­_ì—­ìˆœìœ„': 0.25, ...},
    'ìœ„í—˜ì¤‘ë¦½í˜•': {'ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜': 0.25, 'PER_ì ì •': 0.20, 'ê±°ë˜ëŸ‰_ìˆœìœ„': 0.20, ...},
    'ê³µê²©íˆ¬ìí˜•': {'ê±°ë˜ëŸ‰_ìˆœìœ„': 0.35, 'ë“±ë½ë¥ _ì ˆëŒ€ê°’': 0.30, 'ë³€ë™í­_ìˆœìœ„': 0.20, ...},
}

def score_stocks(df, investor_type):
    weights = WEIGHT_PROFILES.get(investor_type)

    # ì§€í‘œë³„ ì •ê·œí™” í›„ ê°€ì¤‘ì¹˜ ì ìš©
    score = pd.Series(0.0, index=df.index)
    for metric, weight in weights.items():
        score += _normalize_series(df[metric]) * weight

    df['ì¶”ì²œì ìˆ˜'] = score.round(1)
    return df.sort_values('ì¶”ì²œì ìˆ˜', ascending=False)
```

#### (3) íˆ¬ì ì„±í–¥ 5ë‹¨ê³„ ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜

```python
# analyzer.py - classify_investor_type() í•¨ìˆ˜

def classify_investor_type(answers):
    """
    11ë¬¸í•­ ì ìˆ˜ë¥¼ í•©ì‚°í•˜ì—¬ ìµœëŒ€ ê°€ëŠ¥ ì ìˆ˜ ëŒ€ë¹„ ë¹„ìœ¨ë¡œ 5ë‹¨ê³„ ë¶„ë¥˜
    """
    total_score = 0
    max_possible = 0

    for q in SURVEY_QUESTIONS:
        selected_idx = answers.get(q['id'], 0)
        total_score  += q['options'][selected_idx][1]          # ì„ íƒ ì ìˆ˜ í•©ì‚°
        max_possible += max(score for _, score in q['options']) # ìµœëŒ€ ì ìˆ˜ í•©ì‚°

    ratio = total_score / max_possible  # ì ìˆ˜ ë¹„ìœ¨ ê³„ì‚°

    # ë¹„ìœ¨ êµ¬ê°„ë³„ ì„±í–¥ ë¶„ë¥˜
    if   ratio <= 0.25: return 'ì•ˆì •í˜•',    total_score
    elif ratio <= 0.40: return 'ì•ˆì •ì¶”êµ¬í˜•', total_score
    elif ratio <= 0.60: return 'ìœ„í—˜ì¤‘ë¦½í˜•', total_score
    elif ratio <= 0.80: return 'ì ê·¹íˆ¬ìí˜•', total_score
    else:               return 'ê³µê²©íˆ¬ìí˜•', total_score
```

---

### 3-2. `seaborn` / `matplotlib` â€” ì‹œê°í™”

#### (1) seaborn â€” ê±°ë˜ëŸ‰ ê¸‰ì¦ ëª¨ë©˜í…€ ë°” ì°¨íŠ¸

```python
# app.py - RTD ì‹¤ì‹œê°„ ë¶„ì„ íƒ­

import seaborn as sns
import matplotlib.pyplot as plt

fig_surge, ax_surge = plt.subplots(figsize=(8, 5))
fig_surge.patch.set_facecolor('#2b2622')  # ë°°ê²½ìƒ‰ ì§€ì •
ax_surge.set_facecolor('#2b2622')

# seaborn ìˆ˜í‰ ë°” ì°¨íŠ¸ (YlOrBr í™©ê¸ˆ íŒ”ë ˆíŠ¸)
sns.barplot(
    x='ì‹œê°„ë‹¹_ìˆœê±°ë˜ëŸ‰',  # ì§ì „ ì‹œê°„ ëŒ€ë¹„ ì¦ê°€ ê±°ë˜ëŸ‰
    y='ì¢…ëª©ëª…',           # Yì¶•: ì¢…ëª©ëª…
    data=surge_df,        # ê¸‰ì¦ TOP 10 ë°ì´í„°
    palette='YlOrBr_r',   # ì›œ í…Œë§ˆ ìƒ‰ìƒ
    ax=ax_surge
)

# í…ìŠ¤íŠ¸ ìƒ‰ìƒ ì„¤ì • (ë‹¤í¬ ë°°ê²½ ëŒ€ì‘)
ax_surge.tick_params(colors='#f2ece4')
plt.title('ì§ì „ ì‹œê°„ ëŒ€ë¹„ ê±°ë˜ëŸ‰ ìˆœì¦ê°€ TOP 10', color='#dcb98c', fontsize=12)
plt.tight_layout()
st.pyplot(fig_surge)  # Streamlitì— Matplotlib ì°¨íŠ¸ ì‚½ì…
plt.close()           # ë©”ëª¨ë¦¬ í•´ì œ
```

#### (2) matplotlib â€” í˜„ì¬ê°€ ëŒ€ë¹„ ê±°ë˜ëŒ€ê¸ˆ ì‚°ì ë„

```python
# app.py - RTD ì‹¤ì‹œê°„ ë¶„ì„ íƒ­

fig_scatter, ax_scatter = plt.subplots(figsize=(8, 5))
fig_scatter.patch.set_facecolor('#2b2622')
ax_scatter.set_facecolor('#2b2622')

# ì‚°ì ë„ (í˜„ì¬ê°€ vs ê±°ë˜ëŒ€ê¸ˆ)
ax_scatter.scatter(
    latest_df['í˜„ì¬ê°€'],     # Xì¶•: ì£¼ê°€
    latest_df['ê±°ë˜ëŒ€ê¸ˆ'],   # Yì¶•: ë‹¹ì¼ ê±°ë˜ëŒ€ê¸ˆ
    c='#dcb98c',             # ì  ìƒ‰ìƒ
    alpha=0.6,               # íˆ¬ëª…ë„ (ì  ê²¹ì¹¨ ì‹œ ë°€ë„ íŒŒì•…)
    edgecolors='none'
)

plt.xlabel("í˜„ì¬ê°€ (ì›)", color='#f2ece4')
plt.ylabel("ê±°ë˜ëŒ€ê¸ˆ", color='#f2ece4')
plt.title(f'ê°€ê²©ëŒ€ë³„ ê±°ë˜ëŒ€ê¸ˆ ë¶„ì‚° ({latest_time} ê¸°ì¤€)', color='#dcb98c')
st.pyplot(fig_scatter)
plt.close()
```

#### (3) plotly â€” ì¸í„°ë™í‹°ë¸Œ BUY/HOLD/SELL ë°” ì°¨íŠ¸

```python
# app.py - ë¶„ì„ ì‹ í˜¸ í˜ì´ì§€

import plotly.express as px

color_map = {'BUY': '#3fb950', 'HOLD': '#d29922', 'SELL': '#f85149'}

fig_sig = px.bar(
    signals_df,
    x='ì¢…ëª©ëª…',
    y='trend_score',        # ì¶”ì„¸ ì ìˆ˜ ë†’ì´ = ë§‰ëŒ€ ë†’ì´
    color='signal',         # ì‹ í˜¸ì— ë”°ë¼ ìƒ‰ìƒ ë¶„ê¸°
    color_discrete_map=color_map,
    title='ì¢…ëª©ë³„ ì¶”ì„¸ ì ìˆ˜ ë° ë§¤ë§¤ ì‹ í˜¸',
    template='plotly_dark',
)

# BUY/SELL ê¸°ì¤€ì„  ì¶”ê°€
fig_sig.add_hline(y=60, line_dash='dash', line_color='#3fb950',
                  annotation_text='BUY ê¸°ì¤€(60)')
fig_sig.add_hline(y=40, line_dash='dash', line_color='#f85149',
                  annotation_text='SELL ê¸°ì¤€(40)')

st.plotly_chart(fig_sig, use_container_width=True)
```

---

## 4. ëŒ€ì‹œë³´ë“œ(ì›¹ì•±) êµ¬í˜„ _(30ì )_

### 4-1. Streamlit â€” í˜ì´ì§€ êµ¬ì„±

```python
# app.py - ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜

import streamlit as st

# 6ê°œ ë©”ë‰´ ë¼ë””ì˜¤ ë²„íŠ¼
page = st.radio(
    "ë©”ë‰´ ì„ íƒ",
    ["ğŸ  ë©”ì¸ ëŒ€ì‹œë³´ë“œ", "ğŸ“‹ íˆ¬ì ì„±í–¥ ì„¤ë¬¸", "â­ ë§ì¶¤ ì¢…ëª© ì¶”ì²œ",
     "ğŸ“ˆ ë¶„ì„ ì‹ í˜¸",    "ğŸ“° ì¢…ëª© ë‰´ìŠ¤",   "ğŸ“§ ë‰´ìŠ¤ë ˆí„°"],
    label_visibility="collapsed",
)

# í˜ì´ì§€ë³„ ì¡°ê±´ ë¶„ê¸° ë¼ìš°íŒ…
if page == "ğŸ  ë©”ì¸ ëŒ€ì‹œë³´ë“œ":
    show_main_dashboard()
elif page == "ğŸ“‹ íˆ¬ì ì„±í–¥ ì„¤ë¬¸":
    show_survey()
elif page == "â­ ë§ì¶¤ ì¢…ëª© ì¶”ì²œ":
    if not st.session_state['logged_in']:
        st.warning("âš ï¸ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    show_recommendations()
```

### 4-2. ê²°ê³¼ ì‹œê°í™” ì—°ë™ â€” Top 50 ì‹¤ì‹œê°„ ì‹œì„¸ íŒ¨ë„

```python
# app.py - ë©”ì¸ ëŒ€ì‹œë³´ë“œ Top 50 ê·¸ë¦¬ë“œ

top50_df = stock_df.sort_values(by='ê±°ë˜ëŸ‰', ascending=False).head(50)

# 5ì—´ ê·¸ë¦¬ë“œ ë°°ì¹˜
with st.expander("ğŸ‘€ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ í¼ì³ë³´ê¸° (Top 50)", expanded=True):
    cols = st.columns(5)
    for i, row in enumerate(top50_df.itertuples()):
        col_idx = i % 5                          # 5ì—´ë¡œ ìˆœí™˜ ë°°ì¹˜
        label_with_rank = f"{i+1}. {row.ì¢…ëª©ëª…}" # 1. ì‚¼ì„±ì „ì í˜•íƒœ

        cols[col_idx].metric(
            label=label_with_rank,
            value=f"{row.í˜„ì¬ê°€:,}",             # 3ìë¦¬ë§ˆë‹¤ ì‰¼í‘œ (â‚© í‘œê¸°)
            delta=f"{row.ë“±ë½ë¥ }",               # ë“±ë½ë¥  â†’ ì´ˆë¡/ë¹¨ê°• arrow ìë™
            delta_color="normal"
        )
```

### 4-3. íšŒì› ì¸ì¦ ì‹œìŠ¤í…œ â€” bcrypt ë¹„ë°€ë²ˆí˜¸ ì•”í˜¸í™”

```python
# app.py - íšŒì›ê°€ì…/ë¡œê·¸ì¸ êµ¬í˜„

import bcrypt as _bcrypt
import json

def _safe_hash(password: str) -> str:
    """ë¹„ë°€ë²ˆí˜¸ë¥¼ bcryptë¡œ ë‹¨ë°©í–¥ ì•”í˜¸í™”"""
    pw_bytes = password.encode('utf-8')[:72]      # 72ë°”ì´íŠ¸ ì œí•œ ì²˜ë¦¬
    return _bcrypt.hashpw(pw_bytes, _bcrypt.gensalt()).decode('utf-8')

def _safe_verify(password: str, hashed: str) -> bool:
    """ì…ë ¥ ë¹„ë°€ë²ˆí˜¸ì™€ ì €ì¥ëœ í•´ì‹œ ê°’ì„ ì•ˆì „í•˜ê²Œ ë¹„êµ"""
    pw_bytes = password.encode('utf-8')[:72]
    return _bcrypt.checkpw(pw_bytes, hashed.encode('utf-8'))

# íšŒì›ê°€ì… ì‹œ JSON êµ¬ì¡°ë¡œ ì €ì¥
users[new_id] = {
    "user_password": _safe_hash(new_pw),    # ì•”í˜¸í™” ì €ì¥
    "user_email":    new_email,
    "type_id":       "ë¯¸ì •"                  # ì„¤ë¬¸ ì™„ë£Œ ì „ ê¸°ë³¸ê°’
}

# ì„¤ë¬¸ ì™„ë£Œ ì‹œ type_id ìë™ ì—…ë°ì´íŠ¸
if st.session_state.get('logged_in'):
    users[user_id]['type_id'] = investor_type   # ì˜ˆ: 'ìœ„í—˜ì¤‘ë¦½í˜•'
    save_users(users)
    st.toast(f"âœ… íˆ¬ì ì„±í–¥({investor_type}) ì €ì¥ ì™„ë£Œ!")
```

### 4-4. ìë™ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬ â€” UI ì¼ê´€ì„± ìœ ì§€

```python
# scheduler_job.py - APScheduler

from apscheduler.schedulers.background import BackgroundScheduler

scheduler = BackgroundScheduler(timezone='Asia/Seoul')

# í‰ì¼ 09ì‹œ~15ì‹œ ë§¤ ì •ê° ìë™ ì‹¤í–‰
scheduler.add_job(
    job_realtime_market_data,   # ìˆ˜ì§‘ í•¨ìˆ˜
    'cron',
    day_of_week='mon-fri',      # ì£¼ì¤‘ë§Œ
    hour='9-15',                # ì¥ ìš´ì˜ ì‹œê°„
    minute=0                    # ì •ê°
)
scheduler.start()
```

---

## ğŸ“Š ì£¼ìš” ì„±ê³¼ ìš”ì•½

| í‰ê°€ í•­ëª© | êµ¬í˜„ ë‚´ìš© | ì‚¬ìš© ê¸°ìˆ  |
|-----------|-----------|-----------|
| ë°ì´í„° ìˆ˜ì§‘ | KOSPI/KOSDAQ 200ì¢…ëª©, 7ì¼ ê³¼ê±° ì‹œì„¸ | `requests`, `BS4`, `Selenium`, `pykrx` |
| ë°ì´í„° ì •ì œ | ìŒìˆ˜ ì²˜ë¦¬, ì¸ì½”ë”©, íƒ€ì… ë³€í™˜, ê²°ì¸¡ì¹˜ ì²˜ë¦¬ | `pandas`, `re`, `numpy` |
| í†µê³„ ë¶„ì„ | trend_score, ì„±í–¥ë³„ ê°€ì¤‘ ìŠ¤ì½”ì–´ë§ | `pandas`, `numpy` |
| ì‹œê°í™” | ë°”ì°¨íŠ¸, ì‚°ì ë„, íŒŒì´ì°¨íŠ¸, ìº”ë“¤ìŠ¤í‹±, Top50 ê·¸ë¦¬ë“œ | `seaborn`, `matplotlib`, `plotly` |
| ì›¹ì•± êµ¬í˜„ | 6í˜ì´ì§€ ëŒ€ì‹œë³´ë“œ, íšŒì› ì¸ì¦, ì ‘ê·¼ ì œì–´ | `streamlit` |
| ìë™í™” | ì‹œê°„ë³„ ë°ì´í„° ìˆ˜ì§‘ â†’ DB/CSV ì €ì¥ | `apscheduler` |

---

*Â© 2026 1íŒ€ ë¯¸ë‹ˆí”„ë¡œì íŠ¸ â€” ì£¼ì‹ ì¶”ì²œ ì‹œìŠ¤í…œ*
